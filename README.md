# RI-assignment1

## Answers

### Simple tokenizer

-   Collection memory size: 2621544 bytes

-   Vocabulary size: 61050 tokens

-   List the ten first terms (in alphabetic order) that appear in only one document:
    ['aaaaaag', 'aaaauga', 'aaac', 'aaag', 'aaap', 'aaars', 'aabb', 'aacaaaaaaggg', 'aacetaminophen', 'aacgaa']

-   List the ten terms with highest document frequency:
    ['were', 'are', 'was', 'from', 'this', 'that', 'with', 'for', 'and', 'the']

### Improved tokenizer

-   Collection memory size: 5242976 bytes

-   Vocabulary size: 96515 tokens

-   List the ten first terms (in alphabetic order) that appear in only one document:
    ['--and', '--diseas', '--michael', '-1-7', '-1-acid', '-1-antiproteinas', '-1-cyclohexene-1-carboxyl', '-1-defici', '-1-ribosom', '-1-thiophen-2-ylethylideneamino']

-   List the ten terms with highest document frequency:
    ['protein', 'human', 'cell', 'viral', 'diseas', 'result', 'studi', 'use', 'infect', 'virus']
